{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on sagemaker with base pytorch image\n",
    "\n",
    "Here all necessary libraries, variables to start the training.\n",
    "This scenario covers training with default pytorch image, on GPU (1 instance). Training code is in \"code\" directory.\n",
    "!!! NOTE : for VPC training, some additiona settings should be set + we will need a different image, with proxy set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sagemaker\n",
    "import time\n",
    "\n",
    "#get sagemaker session, role and region\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "bucket = \"yourbucker\" \n",
    "kms_key = \"kmskey\"\n",
    "output_path = \"s3://{}/out\".format(bucket)\n",
    "module_dir=\"s3://{}/module\".format(bucket)\n",
    "training_data = \"s3//pathtoyourdata\"\n",
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What below code will do:\n",
    "1. Start an estimator object - an abstraction level class for Pytorch framework\n",
    "2. Pack your code (all content of code directory) and put it to \"module_dir\" s3 path\n",
    "3. Launch a training job in pipe mode\n",
    "4. In code file, you can specify requirements.txt with python modules to install. Pytorch container will do it for you\n",
    "\n",
    "###### A note on Pipe mode with Pytorch:\n",
    "1. It reads bytes from the file you set as training file. In train.py you specify how many bytes are to be read. \n",
    "2. There is a helper created by me for transforming bytes to dataframe (since we have bytes read from object, it might happen it reads half of the row, or half of the object in the row). It is not perfect (it drops cases he cannot decode), but it helps with the transformation. \n",
    "3. Data will be read sequencially, until the EOF, and will start again on next epoch. Each sequence will be transformed in dataframe (by train.py script) and will be fed for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "estimator = PyTorch(\n",
    "    source_dir='code',\n",
    "    entry_point='train.py',\n",
    "    code_location=module_dir,\n",
    "    output_path=output_path,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    output_kms_key=kms_key,\n",
    "    role=role,\n",
    "    instance_count = 1,\n",
    "    instance_type='ml.p2.xlarge',\n",
    "    input_mode='Pipe'\n",
    ")\n",
    "estimator.fit(training_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
